{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d585b8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:00.243628Z",
     "iopub.status.busy": "2024-07-29T07:43:00.243293Z",
     "iopub.status.idle": "2024-07-29T07:43:05.701104Z",
     "shell.execute_reply": "2024-07-29T07:43:05.700339Z"
    },
    "papermill": {
     "duration": 5.468953,
     "end_time": "2024-07-29T07:43:05.703348",
     "exception": false,
     "start_time": "2024-07-29T07:43:00.234395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import errno\n",
    "from torch.cuda.amp import autocast\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "import psutil\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c585ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:05.719277Z",
     "iopub.status.busy": "2024-07-29T07:43:05.718897Z",
     "iopub.status.idle": "2024-07-29T07:43:05.729740Z",
     "shell.execute_reply": "2024-07-29T07:43:05.729024Z"
    },
    "papermill": {
     "duration": 0.020872,
     "end_time": "2024-07-29T07:43:05.731658",
     "exception": false,
     "start_time": "2024-07-29T07:43:05.710786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Configuration:\n",
    "    \n",
    "    # Transformer\n",
    "    transformer =  (\n",
    "                        '/kaggle/input/transformer-offline-no-weights/LaBSE',\n",
    "                        '/kaggle/input/transformer-offline-no-weights/mcontriever-msmarco',\n",
    "                        '/kaggle/input/transformer-offline-no-weights/paraphrase-multilingual-mpnet-base-v2',\n",
    "                        '/kaggle/input/transformer-offline-no-weights/stsb-xlm-r-multilingual',\n",
    "                        '/kaggle/input/transformer-offline-no-weights/xlm-r-100langs-bert-base-nli-stsb-mean-tokens',\n",
    "                    )\n",
    "    \n",
    "    # Weights\n",
    "    checkpoints =  (\n",
    "                        '/kaggle/input/labse-gpu/weights_end.pth',\n",
    "                        '/kaggle/input/mcontriever-msmarco-gpu/weights_end.pth',\n",
    "                        '/kaggle/input/mpnet-gpu/weights_end.pth',\n",
    "                        '/kaggle/input/stsb-xlm-r-gpu/weights_end.pth',\n",
    "                        '/kaggle/input/xlm-r-100langs-gpu/weights_end.pth'\n",
    "                    )\n",
    "    \n",
    "    # Known content IDs\n",
    "    content_ids = (\n",
    "                       '/kaggle/input/labse-gpu/content_ids.pt', \n",
    "                       '/kaggle/input/mcontriever-msmarco-gpu/content_ids.pt',\n",
    "                       '/kaggle/input/mpnet-gpu/content_ids.pt',\n",
    "                       '/kaggle/input/stsb-xlm-r-gpu/content_ids.pt',\n",
    "                       '/kaggle/input/xlm-r-100langs-gpu/content_ids.pt'\n",
    "                  )\n",
    "    \n",
    "    # Known conten features\n",
    "    content_features =  (\n",
    "                         '/kaggle/input/labse-gpu/content_features.pt', \n",
    "                         '/kaggle/input/mcontriever-msmarco-gpu/content_features.pt',\n",
    "                         '/kaggle/input/mpnet-gpu/content_features.pt',\n",
    "                         '/kaggle/input/stsb-xlm-r-gpu/content_features.pt',\n",
    "                         '/kaggle/input/xlm-r-100langs-gpu/content_features.pt'\n",
    "                        ) \n",
    "    \n",
    "    # Known content language\n",
    "    content_language =  (\n",
    "                         '/kaggle/input/labse-gpu/content_language.pt', \n",
    "                         '/kaggle/input/mcontriever-msmarco-gpu/content_language.pt',\n",
    "                         '/kaggle/input/mpnet-gpu/content_language.pt',\n",
    "                         '/kaggle/input/stsb-xlm-r-gpu/content_language.pt',\n",
    "                         '/kaggle/input/xlm-r-100langs-gpu/content_language.pt'\n",
    "                        )\n",
    "\n",
    "    \n",
    "    # Predict \n",
    "    max_len: int = 96             # max len of tokenized topic and content\n",
    "    batch_size: int = 64          # batch size (keep small for max performance/speed)\n",
    "    margin: float = 0.18          # dynamic threshold margin  \n",
    "        \n",
    "    # set num_workers\n",
    "    num_workers: int = psutil.cpu_count(logical=False)  # CPU Cores\n",
    "    \n",
    "    # use GPU \n",
    "    device: str = 'cuda'\n",
    "    gpu_ids: int = (0,)            # (0,1) if T4\n",
    "            \n",
    "    # Testing\n",
    "    verbose: bool     = False      # show progress bar\n",
    "    speed_test: bool  = False      # encode 10000 known contents for speed testing\n",
    "    input_test: bool  = False      # check if all ids are aligned of known content\n",
    "    output_test: bool = False      # use 5000 topics instead of sample submission and evaluate \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bcc9467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:05.746107Z",
     "iopub.status.busy": "2024-07-29T07:43:05.745833Z",
     "iopub.status.idle": "2024-07-29T07:43:05.749469Z",
     "shell.execute_reply": "2024-07-29T07:43:05.748765Z"
    },
    "papermill": {
     "duration": 0.012899,
     "end_time": "2024-07-29T07:43:05.751293",
     "exception": false,
     "start_time": "2024-07-29T07:43:05.738394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Configuration() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8710fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:05.766046Z",
     "iopub.status.busy": "2024-07-29T07:43:05.765788Z",
     "iopub.status.idle": "2024-07-29T07:43:05.832311Z",
     "shell.execute_reply": "2024-07-29T07:43:05.831197Z"
    },
    "papermill": {
     "duration": 0.077092,
     "end_time": "2024-07-29T07:43:05.835060",
     "exception": false,
     "start_time": "2024-07-29T07:43:05.757968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义了transformer和前向传播方法\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "                 transformer_name,\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(transformer_name)\n",
    "        print(self.config)\n",
    "        self.transformer = AutoModel.from_config(config=self.config)  \n",
    "        \n",
    "        self.logit_scale = torch.nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "                \n",
    "    @autocast()\n",
    "    def forward(self, ids, mask): \n",
    "\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out.last_hidden_state\n",
    "        pooled_output = sequence_output[:, 0, :]\n",
    "            \n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91449323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:05.850877Z",
     "iopub.status.busy": "2024-07-29T07:43:05.850597Z",
     "iopub.status.idle": "2024-07-29T07:43:05.861311Z",
     "shell.execute_reply": "2024-07-29T07:43:05.860472Z"
    },
    "papermill": {
     "duration": 0.020566,
     "end_time": "2024-07-29T07:43:05.863194",
     "exception": false,
     "start_time": "2024-07-29T07:43:05.842628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EqualDatasetEval(Dataset):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 text_list,\n",
    "                 ids_list,\n",
    "                 language_list,\n",
    "                 tokenizer,\n",
    "                 max_len):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.text_list = text_list\n",
    "        self.ids_list = ids_list\n",
    "        self.language_list = language_list\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = tokenizer.pad_token_id\n",
    "        \n",
    "        self.max_len = max_len\n",
    "        \n",
    "      \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text_id = self.ids_list[index]\n",
    "        language = self.language_list[index]\n",
    "        \n",
    "        tok = self.tokenizer.encode_plus(self.text_list[index],\n",
    "                                        None,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=self.max_len,\n",
    "                                        padding=\"max_length\",\n",
    "                                        return_token_type_ids=True,\n",
    "                                        truncation=True,\n",
    "                                        return_tensors='pt')\n",
    "        \n",
    "        return tok['input_ids'], tok['attention_mask'], text_id, language\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids_list)\n",
    "            \n",
    "\n",
    "    def smart_batching_collate(self, batch):\n",
    "        \n",
    "        input_ids = [x[0] for x in batch]\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        \n",
    "        mask = [x[1] for x in batch]\n",
    "        mask = torch.cat(mask, dim=0)\n",
    "        \n",
    "        max_seq_length = mask.sum(-1).max().to(torch.long)\n",
    "        \n",
    "        # smart cutoff\n",
    "        input_ids = input_ids[:, :max_seq_length]\n",
    "        mask = mask[:, :max_seq_length]\n",
    "        \n",
    "        text_id =  [x[2] for x in batch]\n",
    "        \n",
    "        language = [x[3] for x in batch]\n",
    "        \n",
    "        return input_ids, mask, text_id, language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3632b4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:05.877815Z",
     "iopub.status.busy": "2024-07-29T07:43:05.877549Z",
     "iopub.status.idle": "2024-07-29T07:43:05.891913Z",
     "shell.execute_reply": "2024-07-29T07:43:05.890950Z"
    },
    "papermill": {
     "duration": 0.023933,
     "end_time": "2024-07-29T07:43:05.893845",
     "exception": false,
     "start_time": "2024-07-29T07:43:05.869912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(config, model, dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if config.verbose:\n",
    "        bar = tqdm(dataloader, total=len(dataloader))\n",
    "    else:\n",
    "        bar = dataloader\n",
    "        \n",
    "    features_list = []\n",
    "    ids_list = []\n",
    "    language_list = []\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for ids, mask, text_id, language_id in bar:\n",
    "            \n",
    "            ids_list.extend(text_id)\n",
    "            language_list.extend(language_id)\n",
    "        \n",
    "            with autocast():\n",
    "\n",
    "                ids = ids.to(config.device)\n",
    "                mask = mask.to(config.device)\n",
    "        \n",
    "                feature = model(ids, mask)\n",
    "                feature = F.normalize(feature, dim=-1)\n",
    "            \n",
    "            # normalize output is fp32 with autocast\n",
    "            features_list.append(feature.to(torch.float16))\n",
    "\n",
    "        features = torch.cat(features_list, dim=0).to(\"cpu\")\n",
    "        \n",
    "    if config.verbose:\n",
    "        bar.close()\n",
    "        \n",
    "    ids_list = np.array(ids_list)\n",
    "    language_list = np.array(language_list)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f\"Time for feature extraction: {t1-t0:.3f} sec\")    \n",
    "        \n",
    "       \n",
    "    return features, ids_list, language_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531af8ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:05.908672Z",
     "iopub.status.busy": "2024-07-29T07:43:05.907986Z",
     "iopub.status.idle": "2024-07-29T07:43:05.914226Z",
     "shell.execute_reply": "2024-07-29T07:43:05.913400Z"
    },
    "papermill": {
     "duration": 0.015641,
     "end_time": "2024-07-29T07:43:05.916181",
     "exception": false,
     "start_time": "2024-07-29T07:43:05.900540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    x = str(x)\n",
    "    if x != \"\" and len(x) > 1:\n",
    "        x = x.strip().strip('\\t').strip('\\n')\n",
    "    return x\n",
    "    \n",
    "def clean_and_cut(x):\n",
    "    x = str(x)\n",
    "    if x != \"\" and len(x) > 1:\n",
    "        x = x.strip().strip('\\t').strip('\\n').replace(\"\", \"\")\n",
    "        x = re.sub(r'http\\S+', '', x)\n",
    "        x = \" \".join(x.split(\" \")[:32])[:256]      \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb6c614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:05.930591Z",
     "iopub.status.busy": "2024-07-29T07:43:05.930315Z",
     "iopub.status.idle": "2024-07-29T07:43:07.387126Z",
     "shell.execute_reply": "2024-07-29T07:43:07.386355Z"
    },
    "papermill": {
     "duration": 1.466603,
     "end_time": "2024-07-29T07:43:07.389446",
     "exception": false,
     "start_time": "2024-07-29T07:43:05.922843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sample_submission = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/sample_submission.csv\", index_col=0)\n",
    "df_topics = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/topics.csv\", index_col=0).fillna({\"title\": \"\", \"description\": \"\"})\n",
    "\n",
    "topic2language = dict(zip(df_topics.index, df_topics[\"language\"]))\n",
    "\n",
    "df_sample_submission[\"language\"] = df_sample_submission.index.map(lambda x : topic2language.get(x, \"unk\"))\n",
    "\n",
    "df_topics = df_topics.replace(to_replace= r'\\r\\n', value= ' ', regex=True)\n",
    "df_topics = df_topics.replace(to_replace= r'\\n', value= ' ', regex=True)\n",
    "\n",
    "df_topics[\"title\"] = df_topics[\"title\"].map(clean)\n",
    "df_topics[\"description\"] = df_topics[\"description\"].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "474d665b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:07.404875Z",
     "iopub.status.busy": "2024-07-29T07:43:07.404184Z",
     "iopub.status.idle": "2024-07-29T07:43:07.415317Z",
     "shell.execute_reply": "2024-07-29T07:43:07.414511Z"
    },
    "papermill": {
     "duration": 0.02068,
     "end_time": "2024-07-29T07:43:07.417238",
     "exception": false,
     "start_time": "2024-07-29T07:43:07.396558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Topic:\n",
    "    def __init__(self, topic_id):\n",
    "        self.id = topic_id\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def parent(self):\n",
    "        parent_id = df_topics.loc[self.id].parent\n",
    "        if pd.isna(parent_id):\n",
    "            return None\n",
    "        else:\n",
    "            return Topic(parent_id)\n",
    "\n",
    "    @property\n",
    "    def ancestors(self):\n",
    "        ancestors = []\n",
    "        parent = self.parent\n",
    "        while parent is not None:\n",
    "            ancestors.append(parent)\n",
    "            parent = parent.parent\n",
    "        return ancestors\n",
    "\n",
    "    @property\n",
    "    def siblings(self):\n",
    "        if not self.parent:\n",
    "            return []\n",
    "        else:\n",
    "            return [topic for topic in self.parent.children if topic != self]\n",
    "\n",
    "    def get_breadcrumbs(self, separator=\" >> \", include_self=True, include_root=True):\n",
    "        ancestors = self.ancestors\n",
    "        if include_self:\n",
    "            ancestors = [self] + ancestors\n",
    "        if not include_root:\n",
    "            ancestors = ancestors[:-1]\n",
    "        #return separator.join(reversed([a.title for a in ancestors]))\n",
    "        return separator.join([a.title for a in ancestors])\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return [Topic(child_id) for child_id in df_topics[df_topics.parent == self.id].index]\n",
    "\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Topic):\n",
    "            return False\n",
    "        return self.id == other.id\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return df_topics.loc[self.id][name]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.title\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<Topic(id={self.id}, title=\\\"{self.title}\\\")>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9f736e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:07.432536Z",
     "iopub.status.busy": "2024-07-29T07:43:07.432243Z",
     "iopub.status.idle": "2024-07-29T07:43:07.562401Z",
     "shell.execute_reply": "2024-07-29T07:43:07.561624Z"
    },
    "papermill": {
     "duration": 0.139706,
     "end_time": "2024-07-29T07:43:07.564598",
     "exception": false,
     "start_time": "2024-07-29T07:43:07.424892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.output_test:\n",
    "    df_correlations = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/correlations.csv\", index_col=0)\n",
    "    topic_test = df_correlations.index.values[:5000]\n",
    "    df_correlations[\"language\"] = df_correlations.index.map(lambda x : topic2language.get(x, \"unk\"))\n",
    "    language_t = df_correlations[\"language\"].values[:5000].tolist()\n",
    "    del df_correlations\n",
    "else:\n",
    "    topic_test = df_sample_submission.index.values \n",
    "    language_t = df_sample_submission[\"language\"].values.tolist()\n",
    "     \n",
    "def get_topic2string(topic_test): \n",
    "    \n",
    "    topic2string = {}\n",
    "\n",
    "    if config.verbose:\n",
    "        bar = tqdm(topic_test, total=len(topic_test))\n",
    "    else:\n",
    "        bar = topic_test\n",
    "\n",
    "    for t in bar:\n",
    "        to = Topic(t)\n",
    "        string = \"{} # {}\".format(to.get_breadcrumbs(separator=\" # \", include_self=True), to.description)\n",
    "        topic2string[t] = string\n",
    "        \n",
    "    return topic2string\n",
    "\n",
    "\n",
    "topic2string = get_topic2string(topic_test)\n",
    "\n",
    "ids_t = topic_test.tolist()\n",
    "\n",
    "text_t = []\n",
    "for t in ids_t:\n",
    "    text_t.append(topic2string[t])\n",
    "    \n",
    "    \n",
    "del df_topics, df_sample_submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9ac0cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:07.579969Z",
     "iopub.status.busy": "2024-07-29T07:43:07.579690Z",
     "iopub.status.idle": "2024-07-29T07:43:07.587340Z",
     "shell.execute_reply": "2024-07-29T07:43:07.586542Z"
    },
    "papermill": {
     "duration": 0.017377,
     "end_time": "2024-07-29T07:43:07.589211",
     "exception": false,
     "start_time": "2024-07-29T07:43:07.571834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.input_test:\n",
    "    \n",
    "    # Check if all pre-extracted features have same order\n",
    "    content_ids_0 = np.array(torch.load(config.content_ids[0]))\n",
    "    content_language_0 = np.array(torch.load(config.content_language[0]))\n",
    "\n",
    "    for i in range(1,len(config.transformer)):\n",
    "\n",
    "        print(\"-\"*30, i, \"-\"*30)\n",
    "\n",
    "        content_ids = np.array(torch.load(config.content_ids[i]))\n",
    "        content_language = np.array(torch.load(config.content_language[i]))\n",
    "        content_features = torch.load(config.content_features[i])\n",
    "\n",
    "        if (content_ids_0 == content_ids).sum() == len(content_ids):\n",
    "            print(\"Sucess: Same order of Content and Content\")\n",
    "        else:\n",
    "            print(\"Error: Content and Conten have not the same order!!!\")\n",
    "\n",
    "        if (content_language_0 == content_language).sum() == len(content_language_0):\n",
    "            print(\"Sucess: Same order of Content Language and Content Language\")\n",
    "        else:\n",
    "            print(\"Error: Content Language and Content Language have not the same order!!!\")\n",
    "            \n",
    "    del content_ids_0, content_language_0, content_features, content_ids\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb231f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:07.603841Z",
     "iopub.status.busy": "2024-07-29T07:43:07.603576Z",
     "iopub.status.idle": "2024-07-29T07:43:29.714711Z",
     "shell.execute_reply": "2024-07-29T07:43:29.713754Z"
    },
    "papermill": {
     "duration": 22.121084,
     "end_time": "2024-07-29T07:43:29.717039",
     "exception": false,
     "start_time": "2024-07-29T07:43:07.595955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght all content:     154047\n",
      "Lenght known content:   154047\n",
      "Lenght unknown content: 0\n"
     ]
    }
   ],
   "source": [
    "df_content = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/content.csv\", index_col=0).fillna({\"title\": \"\", \"description\": \"\", \"text\": \"\"})\n",
    "\n",
    "content_ids = np.array(torch.load(config.content_ids[0]))\n",
    "content_language = np.array(torch.load(config.content_language[0]))\n",
    "\n",
    "# For speed Test on Content\n",
    "if config.speed_test:\n",
    "    known_content = set(content_ids[:-10000])\n",
    "else:\n",
    "    known_content = set(content_ids)\n",
    "      \n",
    "df_content[\"known\"] = df_content.index.map(lambda x : x in known_content)\n",
    "\n",
    "unknown_content_df = df_content[df_content[\"known\"] == False].copy()\n",
    "known_content_df = df_content[df_content[\"known\"] == True]\n",
    "\n",
    "print(\"Lenght all content:    \", len(df_content))\n",
    "print(\"Lenght known content:  \", len(known_content_df))\n",
    "print(\"Lenght unknown content:\", len(unknown_content_df))\n",
    "\n",
    "known_content_ids =  set(known_content_df.index)\n",
    "\n",
    "known_content_selector = []\n",
    "\n",
    "for i, c in enumerate(content_ids):\n",
    "\n",
    "    if c in known_content_ids:\n",
    "        known_content_selector.append(True)\n",
    "    else:\n",
    "        known_content_selector.append(False)\n",
    "        \n",
    "known_content_selector = np.array(known_content_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504835a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:29.733069Z",
     "iopub.status.busy": "2024-07-29T07:43:29.732721Z",
     "iopub.status.idle": "2024-07-29T07:43:29.910425Z",
     "shell.execute_reply": "2024-07-29T07:43:29.909563Z"
    },
    "papermill": {
     "duration": 0.188448,
     "end_time": "2024-07-29T07:43:29.912713",
     "exception": false,
     "start_time": "2024-07-29T07:43:29.724265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of unknown content to process: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New Content\n",
    "unknown_content_df = unknown_content_df.replace(to_replace= r'\\r\\n', value= ' ', regex=True)\n",
    "unknown_content_df = unknown_content_df.replace(to_replace= r'\\n', value= ' ', regex=True)\n",
    "\n",
    "unknown_content_df[\"title\"] = unknown_content_df[\"title\"].map(clean)\n",
    "unknown_content_df[\"description\"] = unknown_content_df[\"description\"].map(clean)\n",
    "unknown_content_df[\"text\"] = unknown_content_df[\"text\"].map(clean_and_cut)\n",
    "\n",
    "unknown_content_df[\"text_cut\"] = unknown_content_df[\"text\"].map(lambda x : \" \".join(x.split(\" \")[:32]))\n",
    "unknown_content_df[\"input\"] = unknown_content_df[\"title\"] + \" # \" + unknown_content_df[\"description\"] + \" # \" +  unknown_content_df[\"text_cut\"]\n",
    "\n",
    "text_c = unknown_content_df[\"input\"].values.tolist()\n",
    "ids_c = unknown_content_df.index.tolist()\n",
    "language_c = unknown_content_df[\"language\"].values.tolist()\n",
    "\n",
    "print(f\"Lenght of unknown content to process: {len(text_c)}\")\n",
    "\n",
    "del df_content, unknown_content_df, known_content_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb514bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:29.928549Z",
     "iopub.status.busy": "2024-07-29T07:43:29.928250Z",
     "iopub.status.idle": "2024-07-29T07:43:29.942775Z",
     "shell.execute_reply": "2024-07-29T07:43:29.941826Z"
    },
    "papermill": {
     "duration": 0.024376,
     "end_time": "2024-07-29T07:43:29.944611",
     "exception": false,
     "start_time": "2024-07-29T07:43:29.920235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features_model(config, text_t, ids_t, language_t, text_c, ids_c, language_c, known_content_selector):\n",
    "    \n",
    "    \n",
    "    for i, t in enumerate(config.transformer):\n",
    "\n",
    "        print(\"\\n{}[Model: {}]{}\".format(20*\"-\", t, 20*\"-\"))\n",
    "\n",
    "        model = Net(transformer_name=t).eval().to(torch.device(config.device))\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(t)\n",
    "    \n",
    "        print(\"Loading Checkpoint:\", config.checkpoints[i])\n",
    "        model.load_state_dict(torch.load(config.checkpoints[i], map_location=torch.device(config.device)), strict=False)\n",
    "        \n",
    "        # Eval\n",
    "        val_dataset_topic = EqualDatasetEval(text_list=text_t,\n",
    "                                             ids_list=ids_t,\n",
    "                                             language_list=language_t,\n",
    "                                             tokenizer=tokenizer,\n",
    "                                             max_len=config.max_len)\n",
    "\n",
    "        val_loader_topic = DataLoader(dataset=val_dataset_topic, \n",
    "                                      batch_size=config.batch_size, \n",
    "                                      shuffle=False,\n",
    "                                      num_workers=config.num_workers,\n",
    "                                      pin_memory=True,\n",
    "                                      collate_fn=val_dataset_topic.smart_batching_collate\n",
    "                                      )\n",
    "        \n",
    "        \n",
    "        topic_features, topic_ids, topic_language = predict(config, model, val_loader_topic)\n",
    "        \n",
    "        torch.save(topic_features, f\"topic_features_{i}.pt\")\n",
    "        \n",
    "        content_ids = np.array(torch.load(config.content_ids[i]))[known_content_selector]\n",
    "        content_language = np.array(torch.load(config.content_language[i]))[known_content_selector]\n",
    "        content_features = torch.load(config.content_features[i])[known_content_selector]\n",
    "        \n",
    "        # if new content update content\n",
    "        if len(text_c) > 0:\n",
    "        \n",
    "\n",
    "            val_dataset_content = EqualDatasetEval(text_list=text_c,\n",
    "                                                   ids_list=ids_c,\n",
    "                                                   language_list=language_c,\n",
    "                                                   tokenizer=tokenizer,\n",
    "                                                   max_len=config.max_len)\n",
    "\n",
    "            val_loader_content = DataLoader(dataset=val_dataset_content, \n",
    "                                            batch_size=config.batch_size, \n",
    "                                            shuffle=False,\n",
    "                                            num_workers=config.num_workers,\n",
    "                                            pin_memory=True,\n",
    "                                            collate_fn=val_dataset_content.smart_batching_collate\n",
    "                                            )\n",
    "\n",
    "       \n",
    "            content_features_new, content_ids_new, content_language_new = predict(config, model, val_loader_content) \n",
    "        \n",
    "            # Add new content\n",
    "            content_ids = np.concatenate([content_ids, content_ids_new])\n",
    "            content_language = np.concatenate([content_language, content_language_new])\n",
    "            content_features = torch.cat([content_features, content_features_new], dim=0)\n",
    "        \n",
    "\n",
    "        torch.save(content_features, f\"content_features_{i}.pt\")\n",
    "                \n",
    "        if i == 0:        \n",
    "            # Save only once cause we checked that for all models the same order\n",
    "            torch.save(topic_ids, f\"topic_ids.pt\")\n",
    "            torch.save(topic_language, f\"topic_language.pt\")\n",
    "\n",
    "            torch.save(content_ids, f\"content_ids.pt\")\n",
    "            torch.save(content_language, f\"content_language.pt\")\n",
    "    \n",
    "        del model, content_features, topic_features\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dbd988d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:43:29.960196Z",
     "iopub.status.busy": "2024-07-29T07:43:29.959949Z",
     "iopub.status.idle": "2024-07-29T07:44:56.386657Z",
     "shell.execute_reply": "2024-07-29T07:44:56.385585Z"
    },
    "papermill": {
     "duration": 86.437056,
     "end_time": "2024-07-29T07:44:56.388783",
     "exception": false,
     "start_time": "2024-07-29T07:43:29.951727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------[Model: /kaggle/input/transformer-offline-no-weights/LaBSE]--------------------\n",
      "BertConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/transformer-offline-no-weights/LaBSE\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 501153\n",
      "}\n",
      "\n",
      "Loading Checkpoint: /kaggle/input/labse-gpu/weights_end.pth\n",
      "Time for feature extraction: 1.280 sec\n",
      "\n",
      "--------------------[Model: /kaggle/input/transformer-offline-no-weights/mcontriever-msmarco]--------------------\n",
      "BertConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/transformer-offline-no-weights/mcontriever-msmarco\",\n",
      "  \"architectures\": [\n",
      "    \"Contriever\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pooling\": \"average\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Loading Checkpoint: /kaggle/input/mcontriever-msmarco-gpu/weights_end.pth\n",
      "Time for feature extraction: 0.138 sec\n",
      "\n",
      "--------------------[Model: /kaggle/input/transformer-offline-no-weights/paraphrase-multilingual-mpnet-base-v2]--------------------\n",
      "XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/transformer-offline-no-weights/paraphrase-multilingual-mpnet-base-v2\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "Loading Checkpoint: /kaggle/input/mpnet-gpu/weights_end.pth\n",
      "Time for feature extraction: 0.203 sec\n",
      "\n",
      "--------------------[Model: /kaggle/input/transformer-offline-no-weights/stsb-xlm-r-multilingual]--------------------\n",
      "XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/transformer-offline-no-weights/stsb-xlm-r-multilingual\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "Loading Checkpoint: /kaggle/input/stsb-xlm-r-gpu/weights_end.pth\n",
      "Time for feature extraction: 0.152 sec\n",
      "\n",
      "--------------------[Model: /kaggle/input/transformer-offline-no-weights/xlm-r-100langs-bert-base-nli-stsb-mean-tokens]--------------------\n",
      "XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/transformer-offline-no-weights/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "Loading Checkpoint: /kaggle/input/xlm-r-100langs-gpu/weights_end.pth\n",
      "Time for feature extraction: 0.126 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features_model(config, text_t, ids_t, language_t, text_c, ids_c, language_c, known_content_selector)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25d24b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:44:56.408080Z",
     "iopub.status.busy": "2024-07-29T07:44:56.407648Z",
     "iopub.status.idle": "2024-07-29T07:44:57.736833Z",
     "shell.execute_reply": "2024-07-29T07:44:57.735868Z"
    },
    "papermill": {
     "duration": 1.341104,
     "end_time": "2024-07-29T07:44:57.738823",
     "exception": false,
     "start_time": "2024-07-29T07:44:56.397719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages: ['bg', 'en', 'pt']\n",
      "\n",
      "Calculate Similiarity for: /kaggle/input/transformer-offline-no-weights/LaBSE\n",
      "\n",
      "Calculate Similiarity for: /kaggle/input/transformer-offline-no-weights/mcontriever-msmarco\n",
      "\n",
      "Calculate Similiarity for: /kaggle/input/transformer-offline-no-weights/paraphrase-multilingual-mpnet-base-v2\n",
      "\n",
      "Calculate Similiarity for: /kaggle/input/transformer-offline-no-weights/stsb-xlm-r-multilingual\n",
      "\n",
      "Calculate Similiarity for: /kaggle/input/transformer-offline-no-weights/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\n",
      "Calculate mean of similiarities of 5 models per language\n",
      "\n",
      "Select content per language using dynamic threshold of 0.18:\n",
      "bg  - (2x6050) - selected: 4\n",
      "en  - (2x65939) - selected: 1\n",
      "pt  - (1x10435) - selected: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_ids =   torch.load(\"topic_ids.pt\")\n",
    "topic_language =  torch.load(\"topic_language.pt\")\n",
    "\n",
    "content_ids = torch.load(\"content_ids.pt\")\n",
    "content_language =  torch.load(\"content_language.pt\")\n",
    "\n",
    "language_count = Counter(topic_language).most_common()\n",
    "language_list = [l for l, _ in language_count]\n",
    "\n",
    "print(\"Languages:\", language_list)\n",
    "\n",
    "language2sim = dict()\n",
    "\n",
    "for i in range(len(config.transformer)):\n",
    "    \n",
    "    topic_features = torch.load(f\"topic_features_{i}.pt\", map_location=torch.device(\"cuda\"))\n",
    "    content_features = torch.load(f\"content_features_{i}.pt\", map_location=torch.device(\"cuda\"))\n",
    "\n",
    "    print(f\"\\nCalculate Similiarity for: {config.transformer[i]}\")\n",
    "\n",
    "    for language in language_list:\n",
    "\n",
    "        language_content_index = content_language==language\n",
    "        language_topic_index = topic_language==language\n",
    "\n",
    "        language_content_ids = content_ids[language_content_index]\n",
    "        language_topic_ids = topic_ids[language_topic_index]\n",
    "\n",
    "        language_content_features = content_features[language_content_index]\n",
    "        language_topic_features = topic_features[language_topic_index] \n",
    "\n",
    "        if len(language_topic_features) > 0 and len(language_content_features) > 0:\n",
    "\n",
    "            if language_topic_features.dim() == 1:\n",
    "                language_topic_features = language_topic_features.unsqueeze(0)\n",
    "\n",
    "            if language_content_features.dim() == 1:\n",
    "                language_content_features = language_content_features.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sim = language_topic_features @ language_content_features.T  \n",
    "\n",
    "            old_sim = language2sim.get(language, None)\n",
    "\n",
    "            if old_sim is None:\n",
    "                language2sim[language] = sim   \n",
    "            else:\n",
    "                language2sim[language] += sim\n",
    "\n",
    "                    \n",
    "del topic_features, content_features     \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "              \n",
    "\n",
    "num_models = len(config.transformer)\n",
    "    \n",
    "topic_list = []\n",
    "content_list = []\n",
    "\n",
    "print(f\"Calculate mean of similiarities of {num_models} models per language\")\n",
    "\n",
    "print(f\"\\nSelect content per language using dynamic threshold of {config.margin}:\")\n",
    "\n",
    "for language in language_list: \n",
    "    \n",
    "    language_content_ids = content_ids[content_language==language]\n",
    "    language_topic_ids = topic_ids[topic_language==language]\n",
    "\n",
    "    # Mean of Similiarities\n",
    "    sim_matrix = language2sim[language] \n",
    "    \n",
    "    #print(f\"Sim MIN: {sim_matrix.min():.3f} - Sim MAX: {sim_matrix.max():.3f} ->  mean for {num_models} models\")\n",
    "    \n",
    "    sim_matrix /= num_models\n",
    "    \n",
    "    #print(f\"Sim MIN: {sim_matrix.min():.3f} - Sim MAX: {sim_matrix.max():.3f}\")\n",
    "    \n",
    "    selection_length = []\n",
    "    \n",
    "    for i in range(len(sim_matrix)):\n",
    "        \n",
    "        topic = language_topic_ids[i]\n",
    "\n",
    "        sim = sim_matrix[i]\n",
    "\n",
    "        th_tmp = sim.max() - config.margin * sim.max()\n",
    "        p_select = (sim >= th_tmp).squeeze()\n",
    "        c_choice = set(language_content_ids[p_select.cpu().numpy()].tolist())\n",
    "        \n",
    "        topic_list.append(topic)\n",
    "        content_list.append(\" \".join(list(c_choice)))\n",
    "        selection_length.append(len(c_choice))\n",
    "\n",
    "    \n",
    "    selection_length = np.array(selection_length).mean()\n",
    "        \n",
    "    print(f\"{language.ljust(3)} - ({sim_matrix.shape[0]}x{sim_matrix.shape[1]}) - selected: {selection_length:.0f}\")    \n",
    "    \n",
    "del sim_matrix, language2sim\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6e234ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:44:57.759025Z",
     "iopub.status.busy": "2024-07-29T07:44:57.758728Z",
     "iopub.status.idle": "2024-07-29T07:44:57.767737Z",
     "shell.execute_reply": "2024-07-29T07:44:57.766894Z"
    },
    "papermill": {
     "duration": 0.021084,
     "end_time": "2024-07-29T07:44:57.769641",
     "exception": false,
     "start_time": "2024-07-29T07:44:57.748557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"topic_id\": topic_list,\n",
    "                              \"content_ids\": content_list})\n",
    "    \n",
    "df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "794ecbc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:44:57.788523Z",
     "iopub.status.busy": "2024-07-29T07:44:57.788253Z",
     "iopub.status.idle": "2024-07-29T07:44:57.792276Z",
     "shell.execute_reply": "2024-07-29T07:44:57.791407Z"
    },
    "papermill": {
     "duration": 0.015432,
     "end_time": "2024-07-29T07:44:57.794097",
     "exception": false,
     "start_time": "2024-07-29T07:44:57.778665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.verbose:\n",
    "    display(df_submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ca74d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:44:57.812948Z",
     "iopub.status.busy": "2024-07-29T07:44:57.812680Z",
     "iopub.status.idle": "2024-07-29T07:44:57.818959Z",
     "shell.execute_reply": "2024-07-29T07:44:57.818103Z"
    },
    "papermill": {
     "duration": 0.017924,
     "end_time": "2024-07-29T07:44:57.820936",
     "exception": false,
     "start_time": "2024-07-29T07:44:57.803012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f2_score(gt, pd):\n",
    "\n",
    "    gt = set(gt)\n",
    "    pd = set(pd)\n",
    "\n",
    "    if len(pd) == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = len(gt.intersection(pd)) / len(pd)\n",
    "\n",
    "\n",
    "    if len(gt) == 0:\n",
    "        recall = 0.0\n",
    "    else:\n",
    "        recall = len(gt.intersection(pd)) / len(gt)\n",
    "\n",
    "\n",
    "    if (4 * precision + recall) == 0.0:\n",
    "        f2 = 0.0\n",
    "    else:\n",
    "        f2 = (5 * precision * recall) / (4 * precision + recall)\n",
    "        \n",
    "    return f2, precision, recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29063b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:44:57.839867Z",
     "iopub.status.busy": "2024-07-29T07:44:57.839600Z",
     "iopub.status.idle": "2024-07-29T07:44:57.847889Z",
     "shell.execute_reply": "2024-07-29T07:44:57.847052Z"
    },
    "papermill": {
     "duration": 0.019971,
     "end_time": "2024-07-29T07:44:57.849848",
     "exception": false,
     "start_time": "2024-07-29T07:44:57.829877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if config.output_test:\n",
    "\n",
    "    df_correlations = pd.read_csv(\"/kaggle/input/learning-equality-curriculum-recommendations/correlations.csv\")\n",
    "\n",
    "    gt_dict = dict()\n",
    "\n",
    "    topics = df_correlations[\"topic_id\"].values\n",
    "    content = df_correlations[\"content_ids\"].values\n",
    "\n",
    "    for i in range(len(topics)):\n",
    "        content_tmp = content[i].split(\" \")\n",
    "        topic_tmp = topics[i]\n",
    "        gt_dict[topic_tmp] = content_tmp\n",
    "        \n",
    "\n",
    "    scores = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    " \n",
    "    for i, t in enumerate(topic_list):\n",
    "        \n",
    "        c = content_list[i].split(\" \")\n",
    "        \n",
    "        gt = gt_dict[t]\n",
    "\n",
    "        f, precision, recall = f2_score(gt, c)\n",
    "\n",
    "        scores.append(f)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "  \n",
    "    f2 = np.array(scores).mean() \n",
    "    precision = np.array(precision_list).mean()\n",
    "    recall = np.array(recall_list).mean()\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print(\"Eval Score: {:.5f} - Precision: {:.5f} - Recall: {:.3f}\".format(f2, precision, recall))\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e63dd",
   "metadata": {
    "papermill": {
     "duration": 0.008622,
     "end_time": "2024-07-29T07:44:57.867392",
     "exception": false,
     "start_time": "2024-07-29T07:44:57.858770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 4786639,
     "sourceId": 39585,
     "sourceType": "competition"
    },
    {
     "datasetId": 3001605,
     "sourceId": 5164910,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3001855,
     "sourceId": 5246639,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3001798,
     "sourceId": 5246644,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3001915,
     "sourceId": 5246645,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3001940,
     "sourceId": 5246654,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3001962,
     "sourceId": 5246657,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 121.954196,
   "end_time": "2024-07-29T07:44:59.398588",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-29T07:42:57.444392",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
